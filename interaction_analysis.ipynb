{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88a1ee3-b0c5-40f4-bbb3-433768c858cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing RGD_280K: 100%|████████████████| 2501/2501 [7:10:09<00:00, 10.32s/it]\n",
      "Processing RGD_370K: 100%|████████████████| 2501/2501 [7:09:29<00:00, 10.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    
    "# List of base directories and their names\n",
    "directories_info = [\n",
    "    {'path': '/pathtofolder/', 'name': 'RGD_280K'},\n",
    "    {'path': '/pathtofolder/', 'name': 'RGD_370K'}\n",
    "]\n",
    "\n",
    "def get_polar_beads(universe, n_chains=360, atoms_per_chain=16):  #adjust n_chains=num of repeats, atoms_per_chain\n",
    "    indices = [0, 3, 4, 6, 8, 13, 15]\n",
    "    polar_beads = []\n",
    "    for n in range(n_chains):\n",
    "        selection_str = 'index ' + ' '.join(map(str, [i + atoms_per_chain * n for i in indices]))\n",
    "        polar_beads.extend(universe.select_atoms(selection_str))\n",
    "    return polar_beads\n",
    "\n",
    "def get_atom_groups(universe, n_chains=360, atoms_per_chain=16):\n",
    "    indices = {\n",
    "        'pi': [10, 11],\n",
    "        'cation': [2],\n",
    "        'negative': [5]\n",
    "    }\n",
    "    atom_groups = {key: [] for key in indices.keys()}\n",
    "    for n in range(n_chains):\n",
    "        for key, offset in indices.items():\n",
    "            selection_str = 'index ' + ' '.join(map(str, [i + atoms_per_chain * n for i in offset]))\n",
    "            atom_group = universe.select_atoms(selection_str)\n",
    "            atom_groups[key].append(atom_group)\n",
    "    return atom_groups\n",
    "\n",
    "def get_apolar_beads(universe, n_chains=360, atoms_per_chain=16):\n",
    "    indices = [1, 14]\n",
    "    apolar_beads = []\n",
    "    for n in range(n_chains):\n",
    "        selection_str = 'index ' + ' '.join(map(str, [i + atoms_per_chain * n for i in indices]))\n",
    "        apolar_beads.extend(universe.select_atoms(selection_str))\n",
    "    return apolar_beads\n",
    "\n",
    "def calculate_hbonds(polar_beads, threshold=5.0):\n",
    "    inter_hbond_count = 0\n",
    "    intra_hbond_count = 0\n",
    "    n_beads = len(polar_beads)\n",
    "    #groups = [list(range(i, i + 80)) for i in range(0, n_beads, 80)]\n",
    "    centers = [bead.position for bead in polar_beads]\n",
    "    for (i, com1), (j, com2) in product(enumerate(centers), repeat=2):\n",
    "        if i < j:\n",
    "            distance = np.linalg.norm(com1 - com2)\n",
    "            if distance < threshold:\n",
    "                group_i = i // 84\n",
    "                group_j = j // 84\n",
    "                if group_i != group_j:\n",
    "                    inter_hbond_count += 1\n",
    "                elif abs(i - j) > 3:\n",
    "                    intra_hbond_count += 1\n",
    "    return inter_hbond_count, intra_hbond_count\n",
    "\n",
    "def calculate_ccs(apolar_beads, threshold=5.0):\n",
    "    inter_cc_count = 0\n",
    "    intra_cc_count = 0\n",
    "    n_beads = len(apolar_beads)\n",
    "    centers = [bead.position for bead in apolar_beads]\n",
    "    for (i, com1), (j, com2) in product(enumerate(centers), repeat=2):\n",
    "        if i < j:\n",
    "            distance = np.linalg.norm(com1 - com2)\n",
    "            if distance < threshold:\n",
    "                group_i = i // 24  #num of apolar beads in one repeat*number of repeat in one chain\n",
    "                group_j = j // 24\n",
    "                if group_i != group_j:\n",
    "                    inter_cc_count += 1\n",
    "                elif abs(i - j) > 0:\n",
    "                    intra_cc_count += 1\n",
    "    return inter_cc_count, intra_cc_count\n",
    "\n",
    "def calculate_distances(centers1, centers2, threshold):\n",
    "    pairs = []\n",
    "    for (i, com1), (j, com2) in product(enumerate(centers1), enumerate(centers2)):\n",
    "        if i != j:\n",
    "            distance = np.linalg.norm(com1 - com2)\n",
    "            if distance < threshold:\n",
    "                pairs.append(((i, j), distance))\n",
    "    return pairs\n",
    "\n",
    "def process_frame(universe, polar_beads, atom_groups, chain_groups, apolar_beads):\n",
    "    def in_same_chain_group(i, j):\n",
    "        return any(i in group and j in group for group in chain_groups)\n",
    "\n",
    "    inter_hbond_count, intra_hbond_count = calculate_hbonds(polar_beads)\n",
    "    inter_cc_count, intra_cc_count = calculate_ccs(apolar_beads)\n",
    "    \n",
    "    centers = {key: np.array([group.center_of_geometry() for group in groups]) for key, groups in atom_groups.items()}\n",
    "    interactions = {\n",
    "        'pi_cation': calculate_distances(centers['pi'], centers['cation'], 5),\n",
    "        'q_q': calculate_distances(centers['negative'], centers['cation'], 5),\n",
    "        'pi_pi': calculate_distances(centers['pi'], centers['pi'], 5)\n",
    "    }\n",
    "    \n",
    "    interaction_results = {}\n",
    "    for key, pairs in interactions.items():\n",
    "        same_chain_pairs = []\n",
    "        diff_chain_pairs = []\n",
    "        for (i, j), distance in pairs:\n",
    "            if in_same_chain_group(i, j):\n",
    "                same_chain_pairs.append(distance)\n",
    "            else:\n",
    "                diff_chain_pairs.append(distance)\n",
    "        interaction_results[key] = {\n",
    "            'same_chain_pairs': same_chain_pairs,\n",
    "            'diff_chain_pairs': diff_chain_pairs\n",
    "        }\n",
    "    \n",
    "    return inter_hbond_count, intra_hbond_count, inter_cc_count, intra_cc_count, interaction_results\n",
    "\n",
    "def analyze_directory(directory_info, stride):\n",
    "    xtc_file = os.path.join(directory_info['path'], 'solute.xtc')\n",
    "    tpr_file = os.path.join(directory_info['path'], 'solute.tpr')\n",
    "    universe = mda.Universe(tpr_file, xtc_file)\n",
    "    polar_beads = get_polar_beads(universe)\n",
    "    atom_groups = get_atom_groups(universe)\n",
    "    apolar_beads = get_apolar_beads(universe)\n",
    "    chain_groups = [list(range(192 * i, 192 * (i + 1))) for i in range(30)]\n",
    "    \n",
    "    inter_frame_counts = []\n",
    "    intra_frame_counts = []\n",
    "    inter_cc_frame_counts = []\n",
    "    intra_cc_frame_counts = []\n",
    "    frame_data = {key: [] for key in ['pi_cation', 'q_q', 'pi_pi']}\n",
    "    \n",
    "    for ts in tqdm(universe.trajectory[2000:7001:stride], desc=f\"Processing {directory_info['name']}\"):\n",
    "        inter_hbond_count, intra_hbond_count, inter_cc_count, intra_cc_count, frame_results = process_frame(\n",
    "            universe, polar_beads, atom_groups, chain_groups, apolar_beads)\n",
    "        inter_frame_counts.append(inter_hbond_count)\n",
    "        intra_frame_counts.append(intra_hbond_count)\n",
    "        inter_cc_frame_counts.append(inter_cc_count)\n",
    "        intra_cc_frame_counts.append(intra_cc_count)\n",
    "        for key in frame_data.keys():\n",
    "            frame_data[key].append(frame_results[key])\n",
    "    \n",
    "    summary = {\n",
    "        'inter_hbonds': {\n",
    "            'total': sum(inter_frame_counts),\n",
    "            'average': np.mean(inter_frame_counts) if inter_frame_counts else 0,\n",
    "            'std': np.std(inter_frame_counts) if inter_frame_counts else 0\n",
    "        },\n",
    "        'intra_hbonds': {\n",
    "            'total': sum(intra_frame_counts),\n",
    "            'average': np.mean(intra_frame_counts) if intra_frame_counts else 0,\n",
    "            'std': np.std(intra_frame_counts) if intra_frame_counts else 0\n",
    "        },\n",
    "        'inter_ccs': {\n",
    "            'total': sum(inter_cc_frame_counts),\n",
    "            'average': np.mean(inter_cc_frame_counts) if inter_cc_frame_counts else 0,\n",
    "            'std': np.std(inter_cc_frame_counts) if inter_cc_frame_counts else 0\n",
    "        },\n",
    "        'intra_ccs': {\n",
    "            'total': sum(intra_cc_frame_counts),\n",
    "            'average': np.mean(intra_cc_frame_counts) if intra_cc_frame_counts else 0,\n",
    "            'std': np.std(intra_cc_frame_counts) if intra_cc_frame_counts else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for key, data in frame_data.items():\n",
    "        total_same_chain_pairs = sum(len(frame['same_chain_pairs']) for frame in data)\n",
    "        total_diff_chain_pairs = sum(len(frame['diff_chain_pairs']) for frame in data)\n",
    "        summary[key] = {\n",
    "            'total_same_chain_pairs': total_same_chain_pairs,\n",
    "            'total_diff_chain_pairs': total_diff_chain_pairs,\n",
    "            'average_same_chain_pairs': np.mean([len(frame['same_chain_pairs']) for frame in data]),\n",
    "            'std_same_chain_pairs': np.std([len(frame['same_chain_pairs']) for frame in data]),\n",
    "            'average_diff_chain_pairs': np.mean([len(frame['diff_chain_pairs']) for frame in data]),\n",
    "            'std_diff_chain_pairs': np.std([len(frame['diff_chain_pairs']) for frame in data])\n",
    "        }\n",
    "    \n",
    "    return directory_info['name'], summary\n",
    "\n",
    "# Main loop over directories\n",
    "time_between_frames = 1\n",
    "desired_interval = 2\n",
    "stride = int(desired_interval / time_between_frames)\n",
    "\n",
    "for directory_info in directories_info:\n",
    "    name, summary = analyze_directory(directory_info, stride)\n",
    "    \n",
    "    with open(f\"{name}_0.5mM_interaction_analysis.txt\", 'w') as f:\n",
    "        f.write(\"type\\tmean_inter\\tstd_inter\\tmean_intra\\tstd_intra\\n\")\n",
    "        f.write(f\"p-p\\t{summary['inter_hbonds']['average']:.2f}\\t{summary['inter_hbonds']['std']:.2f}\\t\"\n",
    "                f\"{summary['intra_hbonds']['average']:.2f}\\t{summary['intra_hbonds']['std']:.2f}\\n\")\n",
    "        f.write(f\"c-c\\t{summary['inter_ccs']['average']:.2f}\\t{summary['inter_ccs']['std']:.2f}\\t\"\n",
    "                f\"{summary['intra_ccs']['average']:.2f}\\t{summary['intra_ccs']['std']:.2f}\\n\")\n",
    "        for interaction_type, data in summary.items():\n",
    "            if interaction_type not in ['inter_hbonds', 'intra_hbonds', 'inter_ccs', 'intra_ccs']:\n",
    "                f.write(f\"{interaction_type}\\t{data['average_diff_chain_pairs']:.2f}\\t{data['std_diff_chain_pairs']:.2f}\\t\"\n",
    "                        f\"{data['average_same_chain_pairs']:.2f}\\t{data['std_same_chain_pairs']:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7818194-5e28-499f-8148-bc66146c7a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
